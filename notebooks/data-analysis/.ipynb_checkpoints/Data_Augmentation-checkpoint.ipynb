{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "In this notebooks we'll develop the functions required to change tagged and untagged strings from a text in order to recreate a bigger dataset. It is imperative to retain the information of the tags, that may change due to differences in lenght.\n",
    "\n",
    "## Imports\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, json, pickle\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/estatutos/tagged/spacy_dataset_2020-5-6.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir, 'rb') as file:\n",
    "    dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset structure and objective function\n",
    "As we can see below, we have a dictionary with the name of the document as keys and more dictionaries as values.\n",
    "The structure is as follows:\n",
    "```python\n",
    "{\n",
    "    \"company_name\" :{\n",
    "        \"doc_id\" : \"original_name\",\n",
    "        \"pages\" : {\n",
    "            'page_number': {\n",
    "                'text_body_coords': [\n",
    "                    [int, int],\n",
    "                    [int, int],\n",
    "                    [int, int],\n",
    "                    [int, int]\n",
    "                ],\n",
    "                'lectura': 'text_containing in that page'\n",
    "            }\n",
    "        },\n",
    "        'text' : 'the concatenated text string of every page',\n",
    "        'entities': {\n",
    "            'search': ['list', 'of', 'entities', 'available', 'to', 'tag'],\n",
    "            'tags': [\n",
    "                {\n",
    "                    'tag': 'name_of_tag',\n",
    "                    'start': int, # where the entity starts on the string\n",
    "                    'finish': int, # same logic as above\n",
    "                    'text': 'string', # with the slice of the text marked before\n",
    "                    'value': 'string', # what it would look like after parsing\n",
    "                    'extra1': 'string', # not used\n",
    "                    'extra2': 'string', #not used\n",
    "                    'index': int, # for multi entity tags\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "         \n",
    "    }\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We're interested in modifying this part\n",
    "```python\n",
    "{\n",
    "    'doc_id' : 'original_name',\n",
    "    'pages' : {\n",
    "        'page_number': {\n",
    "            'text_body_coords': [\n",
    "                [int, int],\n",
    "                [int, int],\n",
    "                [int, int],\n",
    "                [int, int]\n",
    "            ],\n",
    "            'lectura': 'text_containing in that page'\n",
    "        }\n",
    "    },\n",
    "    'text' : 'the concatenated text string of every page',\n",
    "    'entities': {\n",
    "        'search': ['list', 'of', 'entities', 'available', 'to', 'tag'],\n",
    "        'tags': [\n",
    "            {\n",
    "                'tag': 'name_of_tag',\n",
    "                'start': int, # where the entity starts on the string\n",
    "                'finish': int, # same logic as above\n",
    "                'text': 'string', # with the slice of the text marked before\n",
    "                'value': 'string', # what it would look like after parsing\n",
    "                'extra1': 'string', # not used\n",
    "                'extra2': 'string', #not used\n",
    "                'index': int, # for multi entity tags\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#### In order to achieve this, we'll create a class that takes as input that dictionary and modifies accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dataset['confecom_srl.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "We'll create a simple function to transform data to be displayed in notebooks or html using displacy. To achieve this, the final shape of the dictionary should be:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"text\": \"But Google is starting from behind.\",\n",
    "    \"ents\": [{\"start\": 4, \"end\": 10, \"label\": \"ORG\"}],\n",
    "    \"title\": None\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We check our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Here you can find a suite of tools to work with tagged documents. You can render them or \n",
    "    create synthetic documents to supersample your dataset.\n",
    "\n",
    "Classes\n",
    "-------\n",
    "- TaggedDoc\n",
    "    Intended to open tagged documents using the Text Tag Tool.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "class TaggedDoc:\n",
    "    \"\"\"\n",
    "        Takes a tagged document in dictionary format and creates an object.\n",
    "    \n",
    "    Attributes\n",
    "    --------\n",
    "    - TaggedDoc.document\n",
    "        Returns the same dictionary that was provided.\n",
    "    - TaggedDoc.displacy_ents\n",
    "        Returns a list of dictionaries with every entity tagged. Each dictionary contains keys: \n",
    "        `start`, `end` and `label`.\n",
    "    - TaggedDoc.title\n",
    "        Returns the `doc_id` of the document provided.\n",
    "    - TaggedDoc.text\n",
    "        Returns the entire text of the document provided.\n",
    "    - TaggedDoc.text_len\n",
    "        Returns the lenght of the document measured in characters.\n",
    "    - TaggedDoc.ents_df\n",
    "        Returns a pandas.DataFrame object with the entities tagged.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    - TaggedDoc.render\n",
    "    - TaggedDoc.index_augmentation\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, document):\n",
    "        if not isinstance(document, dict):\n",
    "            raise TypeError(f'This class only takes a dictionary as input. You provided a {type(document)}.')\n",
    "        elif [key for key in ['doc_id', 'text', 'entities'] if key not in document.keys()]:\n",
    "            raise KeyError('The dictionary must contain the keys `doc_id`, `text` and `entities`.')\n",
    "        else:\n",
    "            self.document = document\n",
    "            self.title = document.get('doc_id')\n",
    "            self.ents_df = pd.DataFrame(document['entities']['tags'], index=[self.title for x in range(len(document['entities']['tags']))]).sort_values('start')\n",
    "            self.ents = [values.to_dict() for index, values in self.ents_df.iterrows()]\n",
    "            self.document['entities']['tags'] = self.ents\n",
    "            self.displacy_format = self._displacy_transform()\n",
    "            self.displacy_ents = self.displacy_format.get('ents')\n",
    "            self.text = document.get('text')\n",
    "            \n",
    "\n",
    "\n",
    "    def _displacy_transform(self) -> dict:\n",
    "        ent_list = []\n",
    "        \n",
    "        for tag in self.ents:\n",
    "            ent_list.append(\n",
    "                    {\n",
    "                        'start' : tag.get('start'),\n",
    "                        'end' : tag.get('end'),\n",
    "                        'label': tag.get('tag')\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        return {\n",
    "            'text' : self.document.get('text'),\n",
    "            'ents' : ent_list,\n",
    "            'title' : self.document.get('doc_id') \n",
    "        }\n",
    "    \n",
    "    \n",
    "    def render(self, style='ent', jupyter=True, manual=True, page=False):\n",
    "        for _ in self.displacy_format.get('ents'):\n",
    "            if not _.get('start') or not _.get('end') or not _.get('label'):\n",
    "                to_render = {'text': 'Esto es un texto completo con entidades, pero vos no sabes de donde sacarlo.',\n",
    "                             'ents': [{'start': 46, 'end': 49, 'label': 'GIL'}],\n",
    "                             'title': 'Por favor leé la documentación.'}\n",
    "                break\n",
    "            else:\n",
    "                to_render = self.displacy_format\n",
    "                break\n",
    "        displacy.render(to_render, style=style, jupyter=jupyter, manual=manual, page=page)        \n",
    "\n",
    "\n",
    "    def index_augmentation(self):\n",
    "        new_ents = self.ents_df.copy() # careful with this\n",
    "        new_ents = new_ents.sort_values('start')\n",
    "        new_ents.index = range(new_ents.shape[0])\n",
    "        new_ents['len'] = new_ents.text.apply(len)\n",
    "        new_ents['new_len'] = new_ents.new_text.apply(len)\n",
    "        new_ents['diff'] = new_ents['new_len'] - new_ents['len']\n",
    "        indecis = new_ents.loc[new_ents.diff != 0].index.to_list()\n",
    "\n",
    "        for index in indecis:\n",
    "            diff = new_ents.loc[index, 'diff']\n",
    "            new_ents.loc[index, 'end'] = new_ents.loc[index, 'end'] + diff\n",
    "            new_ents.loc[index+1:,'start'] = new_ents.loc[index+1:,'start'] + diff\n",
    "            new_ents.loc[index+1:,'end'] = new_ents.loc[index+1:,'end'] + diff\n",
    "\n",
    "        return [tagged_entity for tagged_entity in new_ents.T.to_dict().values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = TaggedDoc(dataset['krbg.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "## Augmentation functions\n",
    "There are 2 main functions to be developed:\n",
    "1) One or more that create random entities.\n",
    "\n",
    "2) Another that plugs the new entities into the original text and keeps track of the positions.\n",
    "\n",
    "\n",
    "We need to create one or more functions that generate new entities.\n",
    "- ~Name generator: from AFIP~\n",
    "- ~Date generator: 3 different formats, 366 days = 1098 possibilities.~\n",
    "- ~Vigencia generator: both spelled and numerical~ \n",
    "- ~Tipicidad generator: 3 types, 6 categories, rather easy.~\n",
    "- ~Fecha cierre ejercicio generator: spelled, numerical and mixed.~\n",
    "- ~Mandato dir generator: written years, fiscal years, numeric, mixed and different types of undefined.~\n",
    "- ~Razon Social generator: from AFIP~\n",
    "- ~Capital generator: might be tricky~\n",
    "- ~DNI generator: from AFIP~ Random\n",
    "- ~Aportes generator~\n",
    "\n",
    "The rather complicated part is to match strings with different lenghts into the text without loosing track of the position of the others.\n",
    "\n",
    "### 1) Synthetic Dates\n",
    "We are going to generate 2 functions:\n",
    "- One to create dates within a certain time interval.\n",
    "- The other to change the level of formality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import datetime, random\n",
    "from tqdm.autonotebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date_generator(start_year:int=1900, end_year:int=2050, start_month:int=1, end_month:int=12, start_day:int=1, end_day:int=31, mapper:dict=None, seed:int=None) -> datetime.date:\n",
    "    if 0 in [start_day, start_month, start_year, end_month, end_year, end_day]:\n",
    "        warnings.warn('An argument was specified with value 0, returning to default values.')\n",
    "        mapper = {'start_year':1900, \n",
    "                  'end_year':2050, \n",
    "                  'start_month':1, \n",
    "                  'end_month':12, \n",
    "                  'start_day':1, \n",
    "                  'end_day':31}\n",
    "    \n",
    "    if mapper:\n",
    "        start_year = mapper['start_year']\n",
    "        end_year = mapper['end_year']\n",
    "        start_month = mapper['start_month']\n",
    "        end_month = mapper['end_month']\n",
    "        start_day = mapper['start_day']\n",
    "        end_day = mapper['end_day']\n",
    "    \n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "        \n",
    "    start_date = datetime.date(start_year, start_month, start_day)\n",
    "    end_date = datetime.date(end_year, end_month, end_day)\n",
    "    time_between_dates = end_date - start_date\n",
    "    days_between_dates = time_between_dates.days\n",
    "    random_number_of_days = random.randrange(days_between_dates)\n",
    "    random_date = start_date + datetime.timedelta(days=random_number_of_days)\n",
    "    \n",
    "    return random_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2096, 11, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_date_generator(start_year=2000, end_year=2110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "def date_formatter(date: datetime.date, formality: str = 'random', include_year: bool = True) -> str:\n",
    "    formality_list = ['basic', 'basic2', 'mixed', 'mixed2', 'regular', 'formal', 'veryformal', 'random']\n",
    "    \n",
    "    if formality not in formality_list:\n",
    "        raise KeyError(f'Keyword `{formality}` not found. Argument `formality` must be one of {formality_list}.')\n",
    "    elif formality == 'random':\n",
    "        formality = formality_list[random.randint(0,5)]\n",
    "    \n",
    "    month_mapper = {\n",
    "        '01':'Enero',\n",
    "        '02':'Febrero',\n",
    "        '03':'Marzo',\n",
    "        '04':'Abril',\n",
    "        '05':'Mayo',\n",
    "        '06':'Junio',\n",
    "        '07':'Julio',\n",
    "        '08':'Agosto',\n",
    "        '09':'Septiembre',\n",
    "        '10':'Octubre',\n",
    "        '11':'Noviembre',\n",
    "        '12':'Diciembre'}\n",
    "\n",
    "    day = f'{date.day}' if len(str(date.day)) > 1 else f'0{date.day}'\n",
    "    month = f'{date.month}' if len(str(date.month)) > 1 else f'0{date.month}'\n",
    "    \n",
    "    if formality not in ['basic', 'basic2']:\n",
    "        day_words = num2words(day, lang='es', to='cardinal') if formality != 'veryformal' else num2words(day, lang='es', to='ordinal')\n",
    "        month_words = month_mapper[month]\n",
    "    \n",
    "    if include_year:\n",
    "        year = f'{date.year}'    \n",
    "        year_words = num2words(year, lang='es')\n",
    "    \n",
    "    format_mapper = {\n",
    "        'basic': f'{day}-{month}-{year}' if include_year else f'{day}-{month}',\n",
    "        'basic2': f'{day}/{month}/{year}' if include_year else f'{day}/{month}',\n",
    "        'mixed': f'{day} de {month_words} de {year}' if include_year else \\\n",
    "                 f'{day} de {month_words}',\n",
    "        'mixed2':f'{day} de {month_words} de {year_words}' if include_year else \\\n",
    "                 f'{day} de {month_words}',\n",
    "        'regular': f'{day_words} de {month_words} de {year_words}' if include_year else \\\n",
    "                   f'{day_words} de {month_words}',\n",
    "        'formal': f'{day_words} del mes de {month_words} de {year_words}' if include_year\\\n",
    "                  else f'{day_words} del mes de {month_words}',\n",
    "        'veryformal': f'{day_words} día del mes de {month_words} del año {year_words}' \\\n",
    "                    if include_year else f'{day_words} días del mes de {month_words}'\n",
    "    }\n",
    "    result = format_mapper[formality]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05 de Enero de 1844'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_formatter(random_date_generator(start_year=1450, end_year=2110))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Index augmentation\n",
    "\n",
    "This function allows us to mantain the relationship between the slices of each entity. For every extra character replaced, the following entities change their start and finish values. The same happens if the new string is shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_augmentation(self):\n",
    "    new_ents = self.ents_df.copy() # careful with this\n",
    "    new_ents = new_ents.sort_values('start')\n",
    "    new_ents.index = range(new_ents.shape[0])\n",
    "    new_ents['len'] = new_ents.text.apply(len)\n",
    "    new_ents['new_len'] = new_ents.new_text.apply(len)\n",
    "    new_ents['diff'] = new_ents['new_len'] - new_ents['len']\n",
    "    indecis = new_ents.loc[new_ents.diff != 0].index.to_list()\n",
    "\n",
    "    for index in indecis:\n",
    "        diff = new_ents.loc[index, 'diff']\n",
    "        new_ents.loc[index, 'end'] = new_ents.loc[index, 'end'] + diff\n",
    "        new_ents.loc[index+1:,'start'] = new_ents.loc[index+1:,'start'] + diff\n",
    "        new_ents.loc[index+1:,'end'] = new_ents.loc[index+1:,'end'] + diff\n",
    "\n",
    "    return [tagged_entity for tagged_entity in new_ents.T.to_dict().values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Synthetic Names, DNI's and CUIT's\n",
    "We're going to create a function that allows us to take a random name from a database taken from AFIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "names = pd.read_csv('../../data/estatutos/external_sources/afip_names_cuits.csv', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "names['name'] = names.concatenado.apply(lambda x: x[:30] if isinstance(x, str) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "names['name'] = names['name'].str.replace('\\s{2,}', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = names.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Companies and people\n",
    "Since we have companies in the list, we can take them to create synthetic \"Razon Social\". Keep in mind that we'll include them as people's name since they can be founders of a new company as any regular person can. And we're also going to throw away goverments, municipalities, companies in formation and those who filed bankrupcy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are 68352 different companies. We'll use that as a mask to create a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_mask = names['name'].str.contains(r'\\bSA$|\\bSRL$|\\bSAS$|\\bSAU$|\\bSASU$|\\bSAIC$|\\bSACIF$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concatenado</th>\n",
       "      <th>cuit</th>\n",
       "      <th>dni</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68968</th>\n",
       "      <td>DE MIRANDA EURICO SA</td>\n",
       "      <td>20056190415</td>\n",
       "      <td>05619041</td>\n",
       "      <td>DE MIRANDA EURICO SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138919</th>\n",
       "      <td>DE LAVALLAZ ALBERTO ANTONIO SAACEXA</td>\n",
       "      <td>20078365863</td>\n",
       "      <td>07836586</td>\n",
       "      <td>DE LAVALLAZ ALBERTO ANTONIO SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269324</th>\n",
       "      <td>GARCIA CASTELLANOS FERNANDO SANINIF</td>\n",
       "      <td>20111927082</td>\n",
       "      <td>11192708</td>\n",
       "      <td>GARCIA CASTELLANOS FERNANDO SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334800</th>\n",
       "      <td>GRECO FRANCISCO ANTONIO SA    NINIA</td>\n",
       "      <td>20120626575</td>\n",
       "      <td>12062657</td>\n",
       "      <td>GRECO FRANCISCO ANTONIO SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402647</th>\n",
       "      <td>SOLDANO ALVARO GERMAN DEL SA  NINIA</td>\n",
       "      <td>20128898558</td>\n",
       "      <td>12889855</td>\n",
       "      <td>SOLDANO ALVARO GERMAN DEL SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955893</th>\n",
       "      <td>BE3 SRL</td>\n",
       "      <td>34686133305</td>\n",
       "      <td>68613330</td>\n",
       "      <td>BE3 SRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955894</th>\n",
       "      <td>DIFEMA SRL</td>\n",
       "      <td>34686233318</td>\n",
       "      <td>68623331</td>\n",
       "      <td>DIFEMA SRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955895</th>\n",
       "      <td>RUBRO PUBLICIDAD SA</td>\n",
       "      <td>34686233482</td>\n",
       "      <td>68623348</td>\n",
       "      <td>RUBRO PUBLICIDAD SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955896</th>\n",
       "      <td>EAGLEMP TURISMO SRL</td>\n",
       "      <td>34686333320</td>\n",
       "      <td>68633332</td>\n",
       "      <td>EAGLEMP TURISMO SRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955898</th>\n",
       "      <td>FANCON SA</td>\n",
       "      <td>34688233358</td>\n",
       "      <td>68823335</td>\n",
       "      <td>FANCON SA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68352 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  concatenado         cuit       dni  \\\n",
       "68968          DE MIRANDA EURICO SA            20056190415  05619041   \n",
       "138919   DE LAVALLAZ ALBERTO ANTONIO SAACEXA   20078365863  07836586   \n",
       "269324   GARCIA CASTELLANOS FERNANDO SANINIF   20111927082  11192708   \n",
       "334800   GRECO FRANCISCO ANTONIO SA    NINIA   20120626575  12062657   \n",
       "402647   SOLDANO ALVARO GERMAN DEL SA  NINIA   20128898558  12889855   \n",
       "...                                       ...          ...       ...   \n",
       "4955893        BE3 SRL                         34686133305  68613330   \n",
       "4955894        DIFEMA SRL                      34686233318  68623331   \n",
       "4955895        RUBRO PUBLICIDAD SA             34686233482  68623348   \n",
       "4955896        EAGLEMP TURISMO SRL             34686333320  68633332   \n",
       "4955898        FANCON SA                       34688233358  68823335   \n",
       "\n",
       "                                   name  \n",
       "68968              DE MIRANDA EURICO SA  \n",
       "138919   DE LAVALLAZ ALBERTO ANTONIO SA  \n",
       "269324   GARCIA CASTELLANOS FERNANDO SA  \n",
       "334800       GRECO FRANCISCO ANTONIO SA  \n",
       "402647     SOLDANO ALVARO GERMAN DEL SA  \n",
       "...                                 ...  \n",
       "4955893                         BE3 SRL  \n",
       "4955894                      DIFEMA SRL  \n",
       "4955895             RUBRO PUBLICIDAD SA  \n",
       "4955896             EAGLEMP TURISMO SRL  \n",
       "4955898                       FANCON SA  \n",
       "\n",
       "[68352 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.loc[company_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found a problem. The dataset wasn't properly cleaned. As we can see, some people ho have \"SA\" at the end, might have been part of their names. The good part is that it seems that the data frame is sorted. First people, then companies, then goverment bodies. Let's begin with goverment offices, since we really don't need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "guv_name = names['concatenado'].str.contains('GOBIER|MUNICIP|UNIVERSIDA|BIBLIO|ASOCIAC|ESCUELA|COLEGIO|HOSPITAL|SANATORIO|CLINICA|INSTITUT|SECRETA|MINISTER|OFICINA')\n",
    "guv_cuit = names.cuit.str.contains(r'^30|^33|^34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concatenado</th>\n",
       "      <th>cuit</th>\n",
       "      <th>dni</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4482664</th>\n",
       "      <td>ASOCIACION MUTUAL DAN</td>\n",
       "      <td>30500045198</td>\n",
       "      <td>50004519</td>\n",
       "      <td>ASOCIACION MUTUAL DAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482667</th>\n",
       "      <td>ASOCIACION ARGENTINA DE COMPA#</td>\n",
       "      <td>30500048782</td>\n",
       "      <td>50004878</td>\n",
       "      <td>ASOCIACION ARGENTINA DE COMPA#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482685</th>\n",
       "      <td>INSTITUTO AUTARQUICO</td>\n",
       "      <td>30500055509</td>\n",
       "      <td>50005550</td>\n",
       "      <td>INSTITUTO AUTARQUICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482696</th>\n",
       "      <td>INSTITUTO COOPERATIVO</td>\n",
       "      <td>30500060588</td>\n",
       "      <td>50006058</td>\n",
       "      <td>INSTITUTO COOPERATIVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482700</th>\n",
       "      <td>INSTITUTO ASEGURADOR</td>\n",
       "      <td>30500063242</td>\n",
       "      <td>50006324</td>\n",
       "      <td>INSTITUTO ASEGURADOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955887</th>\n",
       "      <td>BIBLIOTECA POPULAR DE LOS</td>\n",
       "      <td>34684033427</td>\n",
       "      <td>68403342</td>\n",
       "      <td>BIBLIOTECA POPULAR DE LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955891</th>\n",
       "      <td>ASOCIACION CIVIL COMITE DE</td>\n",
       "      <td>34685233411</td>\n",
       "      <td>68523341</td>\n",
       "      <td>ASOCIACION CIVIL COMITE DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955899</th>\n",
       "      <td>GOBIERNO DE LA CIUDAD DE</td>\n",
       "      <td>34999032089</td>\n",
       "      <td>99903208</td>\n",
       "      <td>GOBIERNO DE LA CIUDAD DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955901</th>\n",
       "      <td>MUNICIPALIDAD DE LA MATANZA</td>\n",
       "      <td>34999257560</td>\n",
       "      <td>99925756</td>\n",
       "      <td>MUNICIPALIDAD DE LA MATANZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955902</th>\n",
       "      <td>MUNICIPIO DE ORO VERDE</td>\n",
       "      <td>34999257706</td>\n",
       "      <td>99925770</td>\n",
       "      <td>MUNICIPIO DE ORO VERDE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30653 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            concatenado         cuit       dni  \\\n",
       "4482664  ASOCIACION MUTUAL DAN           30500045198  50004519   \n",
       "4482667  ASOCIACION ARGENTINA DE COMPA#  30500048782  50004878   \n",
       "4482685           INSTITUTO AUTARQUICO   30500055509  50005550   \n",
       "4482696          INSTITUTO COOPERATIVO   30500060588  50006058   \n",
       "4482700           INSTITUTO ASEGURADOR   30500063242  50006324   \n",
       "...                                 ...          ...       ...   \n",
       "4955887      BIBLIOTECA POPULAR DE LOS   34684033427  68403342   \n",
       "4955891     ASOCIACION CIVIL COMITE DE   34685233411  68523341   \n",
       "4955899       GOBIERNO DE LA CIUDAD DE   34999032089  99903208   \n",
       "4955901  MUNICIPALIDAD DE LA MATANZA     34999257560  99925756   \n",
       "4955902  MUNICIPIO DE ORO VERDE          34999257706  99925770   \n",
       "\n",
       "                                   name  \n",
       "4482664           ASOCIACION MUTUAL DAN  \n",
       "4482667  ASOCIACION ARGENTINA DE COMPA#  \n",
       "4482685           INSTITUTO AUTARQUICO   \n",
       "4482696          INSTITUTO COOPERATIVO   \n",
       "4482700           INSTITUTO ASEGURADOR   \n",
       "...                                 ...  \n",
       "4955887      BIBLIOTECA POPULAR DE LOS   \n",
       "4955891     ASOCIACION CIVIL COMITE DE   \n",
       "4955899       GOBIERNO DE LA CIUDAD DE   \n",
       "4955901     MUNICIPALIDAD DE LA MATANZA  \n",
       "4955902          MUNICIPIO DE ORO VERDE  \n",
       "\n",
       "[30653 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.loc[guv_name & guv_cuit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, those 30653 entities go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = names.loc[~(guv_name & guv_cuit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go back to extract **Companies** with our acquired knowledge. Plus, we found that some companies have SAS and others S.A.S., so we'll include those as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_mask = names['name'].str.contains(r'\\bSA$|\\bSRL$|\\bSAS$|\\bSAU$|\\bSASU$|\\bSAIC$|\\bSACIF$')\n",
    "company_dots = names['name'].str.contains(r'\\bS\\.A\\.$|\\bS\\.R\\.L\\.$|\\bS\\.A\\.S\\.$|\\bS\\.A\\.U\\.$|\\bS\\.A\\.S\\.U\\.$|\\bS\\.A\\.I\\.C\\.$|\\bS\\.A\\.C\\.I\\.F\\.$')\n",
    "company_spaces = names['name'].str.contains(r'\\bS\\sA$|\\bS\\sR\\sL$|\\bS\\sA\\sS$|\\bS\\sA\\sU$|\\bS\\sA\\sS\\sU$|\\bS\\sA\\sI\\sC$|\\bS\\sA\\sC\\sI\\sF$')\n",
    "company_cuit = names.cuit.str.contains(r'^30|^33|^34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = names.loc[(company_mask | company_dots | company_spaces) & (company_cuit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concatenado</th>\n",
       "      <th>cuit</th>\n",
       "      <th>dni</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4482617</th>\n",
       "      <td>BANCO BBVA ARGENTINA S.A.</td>\n",
       "      <td>30500003193</td>\n",
       "      <td>50000319</td>\n",
       "      <td>BANCO BBVA ARGENTINA S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482625</th>\n",
       "      <td>BANCO DE SAN JUAN S A</td>\n",
       "      <td>30500009442</td>\n",
       "      <td>50000944</td>\n",
       "      <td>BANCO DE SAN JUAN S A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482627</th>\n",
       "      <td>BANCO DE CORRIENTES SA</td>\n",
       "      <td>30500010602</td>\n",
       "      <td>50001060</td>\n",
       "      <td>BANCO DE CORRIENTES SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482634</th>\n",
       "      <td>BANCO DEL CHUBUT S.A.</td>\n",
       "      <td>30500012990</td>\n",
       "      <td>50001299</td>\n",
       "      <td>BANCO DEL CHUBUT S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482636</th>\n",
       "      <td>CHUBB SEGUROS ARGENTINA S A</td>\n",
       "      <td>30500016260</td>\n",
       "      <td>50001626</td>\n",
       "      <td>CHUBB SEGUROS ARGENTINA S A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955893</th>\n",
       "      <td>BE3 SRL</td>\n",
       "      <td>34686133305</td>\n",
       "      <td>68613330</td>\n",
       "      <td>BE3 SRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955894</th>\n",
       "      <td>DIFEMA SRL</td>\n",
       "      <td>34686233318</td>\n",
       "      <td>68623331</td>\n",
       "      <td>DIFEMA SRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955895</th>\n",
       "      <td>RUBRO PUBLICIDAD SA</td>\n",
       "      <td>34686233482</td>\n",
       "      <td>68623348</td>\n",
       "      <td>RUBRO PUBLICIDAD SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955896</th>\n",
       "      <td>EAGLEMP TURISMO SRL</td>\n",
       "      <td>34686333320</td>\n",
       "      <td>68633332</td>\n",
       "      <td>EAGLEMP TURISMO SRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955898</th>\n",
       "      <td>FANCON SA</td>\n",
       "      <td>34688233358</td>\n",
       "      <td>68823335</td>\n",
       "      <td>FANCON SA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205501 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            concatenado         cuit       dni  \\\n",
       "4482617  BANCO BBVA ARGENTINA S.A.       30500003193  50000319   \n",
       "4482625  BANCO DE SAN JUAN S A           30500009442  50000944   \n",
       "4482627  BANCO DE CORRIENTES SA          30500010602  50001060   \n",
       "4482634  BANCO DEL CHUBUT S.A.           30500012990  50001299   \n",
       "4482636  CHUBB SEGUROS ARGENTINA S A     30500016260  50001626   \n",
       "...                                 ...          ...       ...   \n",
       "4955893  BE3 SRL                         34686133305  68613330   \n",
       "4955894  DIFEMA SRL                      34686233318  68623331   \n",
       "4955895  RUBRO PUBLICIDAD SA             34686233482  68623348   \n",
       "4955896  EAGLEMP TURISMO SRL             34686333320  68633332   \n",
       "4955898  FANCON SA                       34688233358  68823335   \n",
       "\n",
       "                                name  \n",
       "4482617    BANCO BBVA ARGENTINA S.A.  \n",
       "4482625        BANCO DE SAN JUAN S A  \n",
       "4482627       BANCO DE CORRIENTES SA  \n",
       "4482634        BANCO DEL CHUBUT S.A.  \n",
       "4482636  CHUBB SEGUROS ARGENTINA S A  \n",
       "...                              ...  \n",
       "4955893                      BE3 SRL  \n",
       "4955894                   DIFEMA SRL  \n",
       "4955895          RUBRO PUBLICIDAD SA  \n",
       "4955896          EAGLEMP TURISMO SRL  \n",
       "4955898                    FANCON SA  \n",
       "\n",
       "[205501 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now LOOK AT THAT.. We went from 68000 to 205500 companies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = companies.drop('concatenado', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.to_csv('../../data/estatutos/external_sources/companies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = names.loc[~((company_mask | company_dots | company_spaces) & (company_cuit)), ['cuit', 'dni', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = persons.loc[~(persons.name=='') | (persons.name=='  ') | (persons.name=='   ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons.to_csv('../../data/estatutos/external_sources/persons.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_name_generator(name_type:str, n:int):\n",
    "    if n > 20000:\n",
    "        warnings.warn('Number of samples too big, could cause the application to break. Returning 20.000 samples.')\n",
    "        n = 20000\n",
    "    possible_types = ['company', 'person', 'any']\n",
    "    if not name_type in possible_types:\n",
    "        raise KeyError(f'{name_type} is not a valid option. Please choose one of the following {possible_types}')\n",
    "    \n",
    "    if name_type == 'company':\n",
    "        names = pd.read_csv('../../data/estatutos/external_sources/companies.csv', dtype=str)['name']\n",
    "    elif name_type == 'person':\n",
    "        names = pd.read_csv('../../data/estatutos/external_sources/persons.csv', dtype=str)['name']\n",
    "    elif name_type == 'any':\n",
    "        persons = pd.read_csv('../../data/estatutos/external_sources/persons.csv', dtype=str)['name'].sample(10000)\n",
    "        companies = pd.read_csv('../../data/estatutos/external_sources/companies.csv', dtype=str)['name'].sample(10000)\n",
    "        names = pd.concat([persons, companies])\n",
    "        del persons, companies\n",
    "    \n",
    "    \n",
    "    result = names.sample(n).to_numpy()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Random Mandato\n",
    "We created a function that returns all the values expected for mandato.\n",
    "We use `np.random.randint(0,3)` at the begining in order to give 2/3 chances of returning a finite number, and 1/3 chances of returning a permanent goverment of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mandato_generator():\n",
    "    if np.random.randint(0,3):\n",
    "        years = np.random.randint(1,11)\n",
    "        keywords = ['años', 'ejercicios'][np.random.randint(0,2)]\n",
    "        years_words = num2words(years, lang='es')\n",
    "        random_year = [years, years_words, f'{years_words} ({years})', f'{years} ({years_words})'][np.random.randint(0,4)]\n",
    "        result = f'{random_year} {keywords}'\n",
    "    else:\n",
    "        result = ['término de duración de la sociedad', 'plazo de duración de la sociedad', 'vencimiento de la sociedad'][np.random.randint(0,3)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dos (2) años'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mandato_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Random Vigencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vigencia_generator():\n",
    "    years = np.random.randint(1,101)\n",
    "    years_words = num2words(years, lang='es')\n",
    "    salad = [years, years_words, f'{years_words} ({years})', f'{years} ({years_words})'][np.random.randint(0,4)]\n",
    "    \n",
    "    return salad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trece'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vigencia_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Random tipicidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipicidad_generator():\n",
    "    company_type = ['sociedad de responsabilidad limitada', \n",
    "                    'sociedad anónima',\n",
    "                    'sociedad por acciones simplificada',\n",
    "                    'sociedad anónima unipersonal',\n",
    "                    'sociedad por acciones simplificada unipersonal'][np.random.randint(0, 5)]\n",
    "    style = ['lower', 'upper', 'title'][np.random.randint(0,3)]\n",
    "    \n",
    "    if style == 'lower':\n",
    "        result = company_type\n",
    "    elif style == 'upper':\n",
    "        result = company_type.upper()\n",
    "    elif style == 'title':\n",
    "        result = company_type.title()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sociedad de responsabilidad limitada'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipicidad_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Random DNI and Random CUIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_generator(cuit=False):\n",
    "    millions = np.random.randint(0,100)\n",
    "    thousands = np.random.randint(0,1000)\n",
    "    hundreds = np.random.randint(0,1000)\n",
    "    \n",
    "    \n",
    "    if thousands < 10:\n",
    "        thousands = f'00{thousands}'\n",
    "    elif thousands < 100:\n",
    "        thousands = f'0{thousands}'\n",
    "    else: \n",
    "        thousands = f'{thousands}'\n",
    "\n",
    "    if hundreds < 10:\n",
    "        hundreds = f'00{hundreds}'\n",
    "    elif hundreds < 100:\n",
    "        hundreds = f'0{hundreds}'\n",
    "    else: \n",
    "        hundreds = f'{hundreds}'\n",
    "        \n",
    "    result = f'{millions}.{thousands}.{hundreds}'\n",
    "\n",
    "    if cuit:\n",
    "        millions = f'0{millions}' if millions < 10 else f'{millions}'\n",
    "        beginning = np.random.randint(20,36)\n",
    "        end = np.random.randint(1,10)\n",
    "        result = f'{beginning}-{millions}{thousands}{hundreds}-{end}'\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21-13349191-9'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_generator(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Random Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_generator(style:str='any'):\n",
    "    millions = np.random.randint(0,2)\n",
    "    thousands = [x for x in range(0,1000, 5)][np.random.randint(0,200)]\n",
    "    hundreds = ['000', '500'][np.random.randint(0,2)]\n",
    "    \n",
    "    if millions:\n",
    "        if len(str(thousands)) == 1:\n",
    "            thousands = f'00{thousands}'\n",
    "        elif len(str(thousands)) == 2:\n",
    "            thousands = f'0{thousands}'\n",
    "        else:\n",
    "            thousands = str(thousands)\n",
    "        \n",
    "        millions = np.random.randint(1,11)\n",
    "        result = f'{millions}.{thousands}.{hundreds}'\n",
    "    else:\n",
    "        result = f'{thousands}.{hundreds}'\n",
    "    \n",
    "    if style == 'any':\n",
    "        style = ['written', 'number', 'mixed'][np.random.randint(0,3)]\n",
    "    \n",
    "    if style == 'written':\n",
    "        result = ''.join(result.split('.'))\n",
    "        result = num2words(result, lang='es')\n",
    "    elif style == 'mixed':\n",
    "        number = ''.join(result.split('.'))\n",
    "        words = num2words(number, lang='es')\n",
    "        result = [f'{words} ($ {result})', f'${result} ({words})'][np.random.randint(0,2)]\n",
    "    elif style == 'number':\n",
    "        pass\n",
    "    else:\n",
    "        raise KeyError('Wrong specification of style. Must be `written`, `number`, `mixed` or `any`')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Aportes generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aporte_generator(share_type:str = 'any'):\n",
    "    thousands = [x for x in range(0,1000, 5)][np.random.randint(0,200)]\n",
    "    hundreds = ['000', '500'][np.random.randint(0,2)]\n",
    "    \n",
    "    if np.random.randint(0,2):\n",
    "        result = f'{thousands}.{hundreds}'\n",
    "    else:\n",
    "        result = thousands\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.000'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aporte_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Domicilio generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open('../../data/estatutos/external_sources/calles.json', 'r') as f:\n",
    "    direcciones = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "calles = [pd.DataFrame(calle) for calle in direcciones['calles']]\n",
    "df_calles = pd.concat(calles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del calles, direcciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calles = df_calles.dropna(subset=['provincia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_calles.provincia.apply(lambda x: x.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_calles = df_calles.loc[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calles = clean_calles.sort_values('id').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calles = df_calles.drop(columns=['index', 'fuente', 'altura'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calles['full'] = df_calles['categoria'].str.lower() + ' ' + df_calles['nombre'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calles.loc[~df_calles.provincia.str.contains('Autónoma'), 'provincia'] = 'Provincia de ' + df_calles.loc[~df_calles.provincia.str.contains('Autónoma'), 'provincia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calles.to_csv('../../data/estatutos/external_sources/calles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calles = pd.read_csv('../../data/estatutos/external_sources/calles.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoria</th>\n",
       "      <th>departamento</th>\n",
       "      <th>nombre</th>\n",
       "      <th>id</th>\n",
       "      <th>provincia</th>\n",
       "      <th>localidad_censal</th>\n",
       "      <th>full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>15 DE NOVIEMBRE DE 1889</td>\n",
       "      <td>0200701000025</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>calle 15 De Noviembre De 1889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>25 DE MAYO</td>\n",
       "      <td>0200701000055</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>calle 25 De Mayo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>5 DE JULIO</td>\n",
       "      <td>0200701000065</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>calle 5 De Julio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>ACCESO</td>\n",
       "      <td>0200701000100</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>calle Acceso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Comuna 1</td>\n",
       "      <td>ACCESO A ALVEAR</td>\n",
       "      <td>0200701000120</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>calle Acceso A Alvear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151367</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>WULAIA</td>\n",
       "      <td>9401502002795</td>\n",
       "      <td>Provincia de Tierra del Fuego, Antártida e Isl...</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>calle Wulaia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151368</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>YAGANES</td>\n",
       "      <td>9401502002800</td>\n",
       "      <td>Provincia de Tierra del Fuego, Antártida e Isl...</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>calle Yaganes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151369</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>YARKEN</td>\n",
       "      <td>9401502002805</td>\n",
       "      <td>Provincia de Tierra del Fuego, Antártida e Isl...</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>calle Yarken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151370</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>YOWEN</td>\n",
       "      <td>9401502002810</td>\n",
       "      <td>Provincia de Tierra del Fuego, Antártida e Isl...</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>calle Yowen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151371</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>ZORRO COLORADO</td>\n",
       "      <td>9401502002815</td>\n",
       "      <td>Provincia de Tierra del Fuego, Antártida e Isl...</td>\n",
       "      <td>Ushuaia</td>\n",
       "      <td>calle Zorro Colorado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151372 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       categoria departamento                   nombre             id  \\\n",
       "0          CALLE     Comuna 1  15 DE NOVIEMBRE DE 1889  0200701000025   \n",
       "1          CALLE     Comuna 1               25 DE MAYO  0200701000055   \n",
       "2          CALLE     Comuna 1               5 DE JULIO  0200701000065   \n",
       "3          CALLE     Comuna 1                   ACCESO  0200701000100   \n",
       "4          CALLE     Comuna 1          ACCESO A ALVEAR  0200701000120   \n",
       "...          ...          ...                      ...            ...   \n",
       "151367     CALLE      Ushuaia                   WULAIA  9401502002795   \n",
       "151368     CALLE      Ushuaia                  YAGANES  9401502002800   \n",
       "151369     CALLE      Ushuaia                   YARKEN  9401502002805   \n",
       "151370     CALLE      Ushuaia                    YOWEN  9401502002810   \n",
       "151371     CALLE      Ushuaia           ZORRO COLORADO  9401502002815   \n",
       "\n",
       "                                                provincia  \\\n",
       "0                         Ciudad Autónoma de Buenos Aires   \n",
       "1                         Ciudad Autónoma de Buenos Aires   \n",
       "2                         Ciudad Autónoma de Buenos Aires   \n",
       "3                         Ciudad Autónoma de Buenos Aires   \n",
       "4                         Ciudad Autónoma de Buenos Aires   \n",
       "...                                                   ...   \n",
       "151367  Provincia de Tierra del Fuego, Antártida e Isl...   \n",
       "151368  Provincia de Tierra del Fuego, Antártida e Isl...   \n",
       "151369  Provincia de Tierra del Fuego, Antártida e Isl...   \n",
       "151370  Provincia de Tierra del Fuego, Antártida e Isl...   \n",
       "151371  Provincia de Tierra del Fuego, Antártida e Isl...   \n",
       "\n",
       "                       localidad_censal                           full  \n",
       "0       Ciudad Autónoma de Buenos Aires  calle 15 De Noviembre De 1889  \n",
       "1       Ciudad Autónoma de Buenos Aires               calle 25 De Mayo  \n",
       "2       Ciudad Autónoma de Buenos Aires               calle 5 De Julio  \n",
       "3       Ciudad Autónoma de Buenos Aires                   calle Acceso  \n",
       "4       Ciudad Autónoma de Buenos Aires          calle Acceso A Alvear  \n",
       "...                                 ...                            ...  \n",
       "151367                          Ushuaia                   calle Wulaia  \n",
       "151368                          Ushuaia                  calle Yaganes  \n",
       "151369                          Ushuaia                   calle Yarken  \n",
       "151370                          Ushuaia                    calle Yowen  \n",
       "151371                          Ushuaia           calle Zorro Colorado  \n",
       "\n",
       "[151372 rows x 7 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def address_generator(n:int, legal:bool=False):\n",
    "    \n",
    "    df_address = pd.read_csv('../../data/estatutos/external_sources/calles.csv', dtype=str)\n",
    "    \n",
    "    if legal:\n",
    "        result = df_address['departamento'] + ', ' + df_address['provincia']\n",
    "        result = result.sample(n)\n",
    "    else:\n",
    "        altura = pd.Series([np.random.randint(0,5000) for i in range(n*5)])\n",
    "        \n",
    "        numeros = [str(np.random.randint(0,10)) for i in range(10)]\n",
    "        letras = 'A B C D E F G H I J'.split(' ')\n",
    "        letras_numeros = letras + numeros\n",
    "        piso = pd.Series([np.random.randint(0,20) for i in range(n*3)])\n",
    "        tipo = pd.Series([['departamento', 'oficina'][np.random.randint(0,2)] for i in range(n*3)])\n",
    "        enumeracion = pd.Series([letras_numeros[np.random.randint(0,20)] for i in range(n*3)])\n",
    "        full = 'piso ' + piso.astype(str) + ', ' + tipo + ' ' + enumeracion.astype(str)\n",
    "        casa = 'casa ' + piso.astype(str) + ', ' + 'manzana' + ' ' + enumeracion.astype(str)\n",
    "        full = pd.concat([full, full, casa]).sample(n*3)\n",
    "        print(len(full))\n",
    "        connector = [[', de la localidad de ', ', partido de ', ', ', ', departamento de ']\\\n",
    "                     [np.random.randint(0,4)] for i in range(n*3)]\n",
    "        \n",
    "        completo =  pd.Series(df_address['nombre'].sample(n*3).str.title().values) + \\\n",
    "                ' ' +\\\n",
    "                pd.Series(altura.sample(n*3).astype(str).values) + \\\n",
    "                ', ' + \\\n",
    "                pd.Series(full.values) + \\\n",
    "                pd.Series(connector) + \\\n",
    "                pd.Series(df_address.sample(n*3)['departamento'].values) + \\\n",
    "                ', ' + \\\n",
    "                pd.Series(df_address.sample(n*3)['provincia'].values)\n",
    "            \n",
    "        solo_altura = pd.Series(df_address['nombre'].sample(n*3).str.title().values) + \\\n",
    "                      ' ' + \\\n",
    "                      pd.Series(altura.sample(n*3).astype(str).values) + \\\n",
    "                      ', ' +\\\n",
    "                      pd.Series(df_address['departamento'].sample(n*3).values) + \\\n",
    "                      ', ' +\\\n",
    "                      pd.Series(df_address['provincia'].sample(n*3).values)\n",
    "        \n",
    "        esta_ciudad = pd.Series(df_address['nombre'].sample(n).str.title().values) + \\\n",
    "                      ' ' + \\\n",
    "                      pd.Series(altura.sample(n).astype(str).values) + \\\n",
    "                      ', ' +\\\n",
    "                      pd.Series(['de esta ciudad' for i in range(n)])\n",
    "        \n",
    "        esta_ciudad_2 = pd.Series(df_address['nombre'].sample(n).str.title().values) + \\\n",
    "                        ' ' +\\\n",
    "                        pd.Series(altura.sample(n).astype(str).values) + \\\n",
    "                        ', ' + \\\n",
    "                        pd.Series(full.sample(n).values) + \\\n",
    "                        pd.Series([', de esta ciudad' for i in range(n)])\n",
    "        \n",
    "        \n",
    "        result = pd.concat([completo, solo_altura, esta_ciudad, esta_ciudad_2]).sample(n).to_list()\n",
    "    \n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
